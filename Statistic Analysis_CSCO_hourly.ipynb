{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate_df(market_data, ticker, zoom=1):\n",
    "    def get_timezoom(x, zoom):\n",
    "        if x[1] != ':':\n",
    "            t = int(x[:2])\n",
    "        else:\n",
    "            t = int(x[0])\n",
    "        return str(t // zoom)\n",
    "\n",
    "    ticker_market = market_data[market_data['SYM_ROOT'] == ticker]\n",
    "    ticker_market['timezoom'] = ticker_market['TIME_M'].apply(lambda x: get_timezoom(x, zoom))\n",
    "    ticker_market['createdate'] = ticker_market['DATE'].apply(lambda x: str(x)) + ' ' + ticker_market['timezoom']\n",
    "    ticker_market = ticker_market[['SIZE', 'PRICE', 'createdate']]\n",
    "\n",
    "    ticker_size = ticker_market.groupby(['createdate']).sum()['SIZE']\n",
    "    ticker_high = ticker_market.groupby(['createdate']).max()['PRICE']\n",
    "    ticker_low = ticker_market.groupby(['createdate']).min()['PRICE']\n",
    "    ticker_open = ticker_market.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[0])\n",
    "    ticker_close = ticker_market.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[-1])\n",
    "    ticker_market_zoom = pd.DataFrame([ticker_size, ticker_high, ticker_low, ticker_open, ticker_close]).T\n",
    "    ticker_market_zoom.columns = ['volume', 'high', 'low', 'open', 'close']\n",
    "\n",
    "    ticker_market_zoom['volatility'] = 2 * (ticker_market_zoom['high'] - ticker_market_zoom['low']) / (\n",
    "                ticker_market_zoom['low'] + ticker_market_zoom['high'])\n",
    "    ticker_market_zoom['return'] = np.log(ticker_market_zoom['close']) / np.log(ticker_market_zoom['open'])\n",
    "\n",
    "    spy = pd.read_csv('SPY.csv')\n",
    "    spy['timezoom'] = spy['TIME_M'].apply(lambda x: get_timezoom(x, zoom))\n",
    "    spy['createdate'] = spy['DATE'].apply(lambda x: str(x)) + ' ' + spy['timezoom']\n",
    "    spy_zoom = pd.DataFrame(columns=['close', 'open'])\n",
    "    spy_zoom['open'] = spy.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[0])\n",
    "    spy_zoom['close'] = spy.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[-1])\n",
    "    spy_zoom['return'] = np.log(spy_zoom['close']) / np.log(spy_zoom['open'])\n",
    "\n",
    "    ticker_market_zoom['excess_return'] = ticker_market_zoom['return'] - spy_zoom['return']\n",
    "    # ticker_market_zoom = ticker_market_zoom[['volume', 'volatility', 'excess_return']]\n",
    "\n",
    "    ticker_tweet = pd.read_csv('./tweets/' + ticker + '.csv', index_col=0)\n",
    "    ticker_tweet['createdate'] = ticker_tweet['createdate'].apply(\n",
    "        lambda x: x[:4] + x[5:7] + x[8:10] + ' ' + str(int(x[12]) // zoom))\n",
    "    ticker_tweet_groupby = ticker_tweet.groupby(['createdate', 'sentiment']).size().unstack()\n",
    "\n",
    "    ticker = ticker_market_zoom.merge(ticker_tweet_groupby, on='createdate', how='outer').iloc[3:, :]\n",
    "\n",
    "    days = ['20201130', '20201201', '20201202', '20201203', '20201204', '20201207', '20201208']\n",
    "    zooms = [i for i in range(int(24 / zoom))]\n",
    "    x = []\n",
    "    for day in days:\n",
    "        for t in zooms:\n",
    "            x.append(day + ' ' + str(t))\n",
    "    empty_df = pd.DataFrame(index=x)\n",
    "    empty_df.index.name = 'createdate'\n",
    "    ticker = empty_df.merge(ticker, on='createdate', how='left').sort_index()\n",
    "    return ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "market_data = pd.read_csv('market_data.csv')\n",
    "ticker = 'CSCO'\n",
    "ticker_df = get_aggregate_df(market_data, ticker, zoom=1)\n",
    "ticker_df = ticker_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ticker_df['G'] = ticker_df['positive'].shift(1)\n",
    "ticker_df['B'] = ticker_df['negative'].shift(1)\n",
    "ticker_df['ER1'] = ticker_df['excess_return'].shift(1)\n",
    "ticker_df['ER2'] = ticker_df['excess_return'].shift(2)\n",
    "ticker_df['VOL1'] = ticker_df['volatility'].shift(1)\n",
    "ticker_df['VOL2'] = ticker_df['volatility'].shift(2)\n",
    "ticker_df['volume1'] = ticker_df['volume'].shift(1)\n",
    "ticker_df['volume2'] = ticker_df['volume'].shift(2)\n",
    "ticker_df = ticker_df.dropna()\n",
    "ticker_df['SR'] = (ticker_df['G']-ticker_df['B'])/(ticker_df['G']+ticker_df['B'])\n",
    "ticker_df['const'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          excess_return   R-squared:                       0.106\n",
      "Model:                            OLS   Adj. R-squared:                 -0.030\n",
      "Method:                 Least Squares   F-statistic:                    0.7805\n",
      "Date:                Thu, 10 Dec 2020   Prob (F-statistic):              0.571\n",
      "Time:                        23:02:52   Log-Likelihood:                 227.26\n",
      "No. Observations:                  39   AIC:                            -442.5\n",
      "Df Residuals:                      33   BIC:                            -432.5\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ER1            0.0747      0.171      0.436      0.665      -0.274       0.423\n",
      "ER2           -0.2351      0.167     -1.412      0.167      -0.574       0.104\n",
      "G          -9.645e-06   1.63e-05     -0.592      0.558   -4.28e-05    2.35e-05\n",
      "B           1.487e-05   5.08e-05      0.293      0.772   -8.85e-05       0.000\n",
      "SR            -0.0002      0.003     -0.060      0.952      -0.007       0.006\n",
      "const          0.0005      0.002      0.307      0.760      -0.003       0.004\n",
      "==============================================================================\n",
      "Omnibus:                        2.424   Durbin-Watson:                   1.962\n",
      "Prob(Omnibus):                  0.298   Jarque-Bera (JB):                1.599\n",
      "Skew:                           0.485   Prob(JB):                        0.450\n",
      "Kurtosis:                       3.204   Cond. No.                     1.14e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.14e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "reg1 = sm.OLS(endog=ticker_df['excess_return'], exog=ticker_df[['ER1', 'ER2', 'G', 'B', 'SR', 'const']], missing='drop')\n",
    "results = reg1.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 volume   R-squared:                       0.176\n",
      "Model:                            OLS   Adj. R-squared:                  0.079\n",
      "Method:                 Least Squares   F-statistic:                     1.819\n",
      "Date:                Thu, 10 Dec 2020   Prob (F-statistic):              0.148\n",
      "Time:                        23:02:52   Log-Likelihood:                -592.40\n",
      "No. Observations:                  39   AIC:                             1195.\n",
      "Df Residuals:                      34   BIC:                             1203.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "volume1       -0.2524      0.168     -1.498      0.143      -0.595       0.090\n",
      "volume2       -0.2066      0.170     -1.216      0.232      -0.552       0.139\n",
      "G           -1.76e+04   8846.825     -1.989      0.055   -3.56e+04     379.726\n",
      "B           2.451e+04   2.25e+04      1.088      0.284   -2.13e+04    7.03e+04\n",
      "const       1.448e+06   6.47e+05      2.239      0.032    1.34e+05    2.76e+06\n",
      "==============================================================================\n",
      "Omnibus:                       18.341   Durbin-Watson:                   1.929\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.500\n",
      "Skew:                           1.529   Prob(JB):                     1.30e-05\n",
      "Kurtosis:                       5.121   Cond. No.                     4.41e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.41e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "reg2 = sm.OLS(endog=ticker_df['volume'], exog=ticker_df[['volume1', 'volume2', 'G', 'B', 'const']], missing='drop')\n",
    "results2 = reg2.fit()\n",
    "\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             volatility   R-squared:                       0.029\n",
      "Model:                            OLS   Adj. R-squared:                 -0.086\n",
      "Method:                 Least Squares   F-statistic:                    0.2514\n",
      "Date:                Thu, 10 Dec 2020   Prob (F-statistic):              0.907\n",
      "Time:                        23:02:52   Log-Likelihood:                 124.41\n",
      "No. Observations:                  39   AIC:                            -238.8\n",
      "Df Residuals:                      34   BIC:                            -230.5\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "VOL1           0.0120      0.172      0.070      0.945      -0.337       0.361\n",
      "VOL2          -0.1406      0.171     -0.821      0.418      -0.489       0.208\n",
      "G          -3.653e-05   9.33e-05     -0.392      0.698      -0.000       0.000\n",
      "B           -3.61e-05      0.000     -0.159      0.875      -0.000       0.000\n",
      "const          0.0113      0.007      1.723      0.094      -0.002       0.025\n",
      "==============================================================================\n",
      "Omnibus:                       78.420   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1248.841\n",
      "Skew:                           4.927   Prob(JB):                    6.57e-272\n",
      "Kurtosis:                      28.912   Cond. No.                     8.16e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.16e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "reg3 = sm.OLS(endog=ticker_df['volatility'], exog=ticker_df[['VOL1', 'VOL2', 'G', 'B', 'const']], missing='drop')\n",
    "results3 = reg3.fit()\n",
    "\n",
    "print(results3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./regression results/'+'CSCO hourly'+' excess return.txt', 'w') as fh1:\n",
    "    fh1.write(results.summary().as_text())\n",
    "with open('./regression results/'+'CSCO hourly'+' volume.txt', 'w') as fh2:\n",
    "    fh2.write(results2.summary().as_text())\n",
    "with open('./regression results/'+'CSCO hourly'+' volatility.txt', 'w') as fh3:\n",
    "    fh3.write(results3.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
