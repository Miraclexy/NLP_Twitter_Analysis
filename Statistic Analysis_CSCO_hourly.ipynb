{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate_df(market_data, ticker, zoom=1):\n",
    "    def get_timezoom(x, zoom):\n",
    "        if x[1] != ':':\n",
    "            t = int(x[:2])\n",
    "        else:\n",
    "            t = int(x[0])\n",
    "        return str(t // zoom)\n",
    "\n",
    "    ticker_market = market_data[market_data['SYM_ROOT'] == ticker]\n",
    "    ticker_market['timezoom'] = ticker_market['TIME_M'].apply(lambda x: get_timezoom(x, zoom))\n",
    "    ticker_market['createdate'] = ticker_market['DATE'].apply(lambda x: str(x)) + ' ' + ticker_market['timezoom']\n",
    "    ticker_market = ticker_market[['SIZE', 'PRICE', 'createdate']]\n",
    "\n",
    "    ticker_size = ticker_market.groupby(['createdate']).sum()['SIZE']\n",
    "    ticker_high = ticker_market.groupby(['createdate']).max()['PRICE']\n",
    "    ticker_low = ticker_market.groupby(['createdate']).min()['PRICE']\n",
    "    ticker_open = ticker_market.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[0])\n",
    "    ticker_close = ticker_market.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[-1])\n",
    "    ticker_market_zoom = pd.DataFrame([ticker_size, ticker_high, ticker_low, ticker_open, ticker_close]).T\n",
    "    ticker_market_zoom.columns = ['volume', 'high', 'low', 'open', 'close']\n",
    "\n",
    "    ticker_market_zoom['volatility'] = 2 * (ticker_market_zoom['high'] - ticker_market_zoom['low']) / (\n",
    "                ticker_market_zoom['low'] + ticker_market_zoom['high'])\n",
    "    ticker_market_zoom['return'] = np.log(ticker_market_zoom['close']) / np.log(ticker_market_zoom['open'])\n",
    "\n",
    "    spy = pd.read_csv('SPY.csv')\n",
    "    spy['timezoom'] = spy['TIME_M'].apply(lambda x: get_timezoom(x, zoom))\n",
    "    spy['createdate'] = spy['DATE'].apply(lambda x: str(x)) + ' ' + spy['timezoom']\n",
    "    spy_zoom = pd.DataFrame(columns=['close', 'open'])\n",
    "    spy_zoom['open'] = spy.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[0])\n",
    "    spy_zoom['close'] = spy.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[-1])\n",
    "    spy_zoom['return'] = np.log(spy_zoom['close']) / np.log(spy_zoom['open'])\n",
    "\n",
    "    ticker_market_zoom['excess_return'] = ticker_market_zoom['return'] - spy_zoom['return']\n",
    "    # ticker_market_zoom = ticker_market_zoom[['volume', 'volatility', 'excess_return']]\n",
    "\n",
    "    ticker_tweet = pd.read_csv('./tweets/' + ticker + '.csv', index_col=0)\n",
    "    ticker_tweet['createdate'] = ticker_tweet['createdate'].apply(\n",
    "        lambda x: x[:4] + x[5:7] + x[8:10] + ' ' + str(int(x[12]) // zoom))\n",
    "    ticker_tweet_groupby = ticker_tweet.groupby(['createdate', 'sentiment']).size().unstack()\n",
    "\n",
    "    ticker = ticker_market_zoom.merge(ticker_tweet_groupby, on='createdate', how='outer').iloc[3:, :]\n",
    "\n",
    "    days = ['20201130', '20201201', '20201202', '20201203', '20201204', '20201207', '20201208']\n",
    "    zooms = [i for i in range(int(24 / zoom))]\n",
    "    x = []\n",
    "    for day in days:\n",
    "        for t in zooms:\n",
    "            x.append(day + ' ' + str(t))\n",
    "    empty_df = pd.DataFrame(index=x)\n",
    "    empty_df.index.name = 'createdate'\n",
    "    ticker = empty_df.merge(ticker, on='createdate', how='left').sort_index()\n",
    "    return ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "market_data = pd.read_csv('market_data.csv')\n",
    "ticker = 'CSCO'\n",
    "ticker_df = get_aggregate_df(market_data, ticker, zoom=1)\n",
    "ticker_df = ticker_df.fillna({'negative':0.0, 'neutral':0.0, 'positive':0.0})\n",
    "\n",
    "ticker_df = ticker_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df['excess_return'] = (ticker_df['excess_return']-np.mean(ticker_df['excess_return']))/np.std(ticker_df['excess_return'])\n",
    "ticker_df['excess_return'] = (ticker_df['volatility']-np.mean(ticker_df['volatility']))/np.std(ticker_df['volatility'])\n",
    "ticker_df['volume'] = (ticker_df['volume']-np.mean(ticker_df['volume']))/np.std(ticker_df['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ticker_df['G'] = ticker_df['positive'].shift(1)\n",
    "ticker_df['B'] = ticker_df['negative'].shift(1)\n",
    "ticker_df['ER1'] = ticker_df['excess_return'].shift(1)\n",
    "ticker_df['ER2'] = ticker_df['excess_return'].shift(2)\n",
    "ticker_df['VOL1'] = ticker_df['volatility'].shift(1)\n",
    "ticker_df['VOL2'] = ticker_df['volatility'].shift(2)\n",
    "ticker_df['volume1'] = ticker_df['volume'].shift(1)\n",
    "ticker_df['volume2'] = ticker_df['volume'].shift(2)\n",
    "ticker_df = ticker_df.dropna()\n",
    "ticker_df['SR'] = (ticker_df['G']-ticker_df['B'])/(ticker_df['G']+ticker_df['B'])\n",
    "ticker_df['const'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          excess_return   R-squared:                       0.029\n",
      "Model:                            OLS   Adj. R-squared:                 -0.114\n",
      "Method:                 Least Squares   F-statistic:                    0.2019\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):              0.959\n",
      "Time:                        13:52:46   Log-Likelihood:                -72.702\n",
      "No. Observations:                  40   AIC:                             157.4\n",
      "Df Residuals:                      34   BIC:                             167.5\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ER1            0.0599      0.184      0.325      0.747      -0.315       0.435\n",
      "ER2            0.0104      0.738      0.014      0.989      -1.490       1.511\n",
      "G             -0.0135      0.033     -0.409      0.685      -0.081       0.054\n",
      "B              0.0130      0.105      0.123      0.903      -0.201       0.227\n",
      "SR             2.0546      6.765      0.304      0.763     -11.693      15.802\n",
      "const         -0.1973      3.748     -0.053      0.958      -7.815       7.420\n",
      "==============================================================================\n",
      "Omnibus:                       70.384   Durbin-Watson:                   2.028\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              794.829\n",
      "Skew:                           4.268   Prob(JB):                    2.54e-173\n",
      "Kurtosis:                      23.101   Cond. No.                     2.39e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.39e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "reg1 = sm.OLS(endog=ticker_df['excess_return'], exog=ticker_df[['ER1', 'ER2', 'G', 'B', 'SR', 'const']], missing='drop')\n",
    "results = reg1.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 volume   R-squared:                       0.111\n",
      "Model:                            OLS   Adj. R-squared:                  0.077\n",
      "Method:                 Least Squares   F-statistic:                     3.243\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):             0.0150\n",
      "Time:                        13:52:46   Log-Likelihood:                -149.11\n",
      "No. Observations:                 109   AIC:                             308.2\n",
      "Df Residuals:                     104   BIC:                             321.7\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "volume1        0.2672      0.098      2.714      0.008       0.072       0.462\n",
      "volume2       -0.1608      0.102     -1.576      0.118      -0.363       0.042\n",
      "G             -0.0055      0.006     -0.880      0.381      -0.018       0.007\n",
      "B              0.0025      0.020      0.126      0.900      -0.037       0.042\n",
      "const          0.1220      0.119      1.027      0.307      -0.114       0.357\n",
      "==============================================================================\n",
      "Omnibus:                      133.873   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3816.149\n",
      "Skew:                           4.192   Prob(JB):                         0.00\n",
      "Kurtosis:                      30.748   Cond. No.                         64.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "reg2 = sm.OLS(endog=ticker_df['volume'], exog=ticker_df[['volume1', 'volume2', 'G', 'B', 'const']], missing='drop')\n",
    "results2 = reg2.fit()\n",
    "\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             volatility   R-squared:                       0.026\n",
      "Model:                            OLS   Adj. R-squared:                 -0.011\n",
      "Method:                 Least Squares   F-statistic:                    0.6985\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):              0.595\n",
      "Time:                        13:52:46   Log-Likelihood:                 386.42\n",
      "No. Observations:                 109   AIC:                            -762.8\n",
      "Df Residuals:                     104   BIC:                            -749.4\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "VOL1           0.1008      0.098      1.034      0.304      -0.093       0.294\n",
      "VOL2          -0.0429      0.099     -0.432      0.666      -0.240       0.154\n",
      "G            4.24e-05   4.53e-05      0.936      0.352   -4.75e-05       0.000\n",
      "B          -7.932e-05      0.000     -0.538      0.592      -0.000       0.000\n",
      "const          0.0055      0.001      4.430      0.000       0.003       0.008\n",
      "==============================================================================\n",
      "Omnibus:                      171.740   Durbin-Watson:                   2.039\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10127.252\n",
      "Skew:                           6.043   Prob(JB):                         0.00\n",
      "Kurtosis:                      48.648   Cond. No.                     7.22e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.22e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "reg3 = sm.OLS(endog=ticker_df['volatility'], exog=ticker_df[['VOL1', 'VOL2', 'G', 'B', 'const']], missing='drop')\n",
    "results3 = reg3.fit()\n",
    "\n",
    "print(results3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./regression results/'+'CSCO hourly'+' excess return.txt', 'w') as fh1:\n",
    "    fh1.write(results.summary().as_text())\n",
    "with open('./regression results/'+'CSCO hourly'+' volume.txt', 'w') as fh2:\n",
    "    fh2.write(results2.summary().as_text())\n",
    "with open('./regression results/'+'CSCO hourly'+' volatility.txt', 'w') as fh3:\n",
    "    fh3.write(results3.summary().as_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
