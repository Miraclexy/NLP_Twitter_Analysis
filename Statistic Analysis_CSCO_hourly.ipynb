{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate_df(market_data, ticker, zoom=1):\n",
    "    def get_timezoom(x, zoom):\n",
    "        if x[1] != ':':\n",
    "            t = int(x[:2])\n",
    "        else:\n",
    "            t = int(x[0])\n",
    "        return str(t // zoom)\n",
    "\n",
    "    ticker_market = market_data[market_data['SYM_ROOT'] == ticker]\n",
    "    ticker_market['timezoom'] = ticker_market['TIME_M'].apply(lambda x: get_timezoom(x, zoom))\n",
    "    ticker_market['createdate'] = ticker_market['DATE'].apply(lambda x: str(x)) + ' ' + ticker_market['timezoom']\n",
    "    ticker_market = ticker_market[['SIZE', 'PRICE', 'createdate']]\n",
    "\n",
    "    ticker_size = ticker_market.groupby(['createdate']).sum()['SIZE']\n",
    "    ticker_high = ticker_market.groupby(['createdate']).max()['PRICE']\n",
    "    ticker_low = ticker_market.groupby(['createdate']).min()['PRICE']\n",
    "    ticker_open = ticker_market.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[0])\n",
    "    ticker_close = ticker_market.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[-1])\n",
    "    ticker_market_zoom = pd.DataFrame([ticker_size, ticker_high, ticker_low, ticker_open, ticker_close]).T\n",
    "    ticker_market_zoom.columns = ['volume', 'high', 'low', 'open', 'close']\n",
    "\n",
    "    ticker_market_zoom['volatility'] = 2 * (ticker_market_zoom['high'] - ticker_market_zoom['low']) / (\n",
    "                ticker_market_zoom['low'] + ticker_market_zoom['high'])\n",
    "    ticker_market_zoom['return'] = np.log(ticker_market_zoom['close']) / np.log(ticker_market_zoom['open'])\n",
    "\n",
    "    spy = pd.read_csv('SPY.csv')\n",
    "    spy['timezoom'] = spy['TIME_M'].apply(lambda x: get_timezoom(x, zoom))\n",
    "    spy['createdate'] = spy['DATE'].apply(lambda x: str(x)) + ' ' + spy['timezoom']\n",
    "    spy_zoom = pd.DataFrame(columns=['close', 'open'])\n",
    "    spy_zoom['open'] = spy.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[0])\n",
    "    spy_zoom['close'] = spy.groupby(['createdate'])['PRICE'].apply(lambda x: x.iloc[-1])\n",
    "    spy_zoom['return'] = np.log(spy_zoom['close']) / np.log(spy_zoom['open'])\n",
    "\n",
    "    ticker_market_zoom['excess_return'] = ticker_market_zoom['return'] - spy_zoom['return']\n",
    "    # ticker_market_zoom = ticker_market_zoom[['volume', 'volatility', 'excess_return']]\n",
    "\n",
    "    ticker_tweet = pd.read_csv('./tweets/' + ticker + '.csv', index_col=0)\n",
    "    ticker_tweet['createdate'] = ticker_tweet['createdate'].apply(\n",
    "        lambda x: x[:4] + x[5:7] + x[8:10] + ' ' + str(int(x[12]) // zoom))\n",
    "    ticker_tweet_groupby = ticker_tweet.groupby(['createdate', 'sentiment']).size().unstack()\n",
    "\n",
    "    ticker = ticker_market_zoom.merge(ticker_tweet_groupby, on='createdate', how='outer').iloc[3:, :]\n",
    "\n",
    "    days = ['20201130', '20201201', '20201202', '20201203', '20201204', '20201207', '20201208']\n",
    "    zooms = [i for i in range(int(24 / zoom))]\n",
    "    x = []\n",
    "    for day in days:\n",
    "        for t in zooms:\n",
    "            x.append(day + ' ' + str(t))\n",
    "    empty_df = pd.DataFrame(index=x)\n",
    "    empty_df.index.name = 'createdate'\n",
    "    ticker = empty_df.merge(ticker, on='createdate', how='left').sort_index()\n",
    "    return ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "market_data = pd.read_csv('market_data.csv')\n",
    "ticker = 'CSCO'\n",
    "ticker_df = get_aggregate_df(market_data, ticker, zoom=1)\n",
    "ticker_df = ticker_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df['excess_return'] = (ticker_df['excess_return']-np.mean(ticker_df['excess_return']))/np.std(ticker_df['excess_return'])\n",
    "ticker_df['excess_return'] = (ticker_df['volatility']-np.mean(ticker_df['volatility']))/np.std(ticker_df['volatility'])\n",
    "ticker_df['volume'] = (ticker_df['volume']-np.mean(ticker_df['volume']))/np.std(ticker_df['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ticker_df['G'] = ticker_df['positive'].shift(1)\n",
    "ticker_df['B'] = ticker_df['negative'].shift(1)\n",
    "ticker_df['ER1'] = ticker_df['excess_return'].shift(1)\n",
    "ticker_df['ER2'] = ticker_df['excess_return'].shift(2)\n",
    "ticker_df['VOL1'] = ticker_df['volatility'].shift(1)\n",
    "ticker_df['VOL2'] = ticker_df['volatility'].shift(2)\n",
    "ticker_df['volume1'] = ticker_df['volume'].shift(1)\n",
    "ticker_df['volume2'] = ticker_df['volume'].shift(2)\n",
    "ticker_df = ticker_df.dropna()\n",
    "ticker_df['SR'] = (ticker_df['G']-ticker_df['B'])/(ticker_df['G']+ticker_df['B'])\n",
    "ticker_df['const'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          excess_return   R-squared:                       0.032\n",
      "Model:                            OLS   Adj. R-squared:                 -0.115\n",
      "Method:                 Least Squares   F-statistic:                    0.2182\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):              0.952\n",
      "Time:                        00:04:35   Log-Likelihood:                -55.534\n",
      "No. Observations:                  39   AIC:                             123.1\n",
      "Df Residuals:                      33   BIC:                             133.1\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ER1            0.0037      0.176      0.021      0.983      -0.354       0.361\n",
      "ER2           -0.1385      0.174     -0.797      0.431      -0.492       0.215\n",
      "G              0.0031      0.023      0.139      0.891      -0.043       0.049\n",
      "B             -0.0260      0.071     -0.367      0.716      -0.170       0.118\n",
      "SR            -1.5260      4.567     -0.334      0.740     -10.818       7.766\n",
      "const          1.1848      2.526      0.469      0.642      -3.954       6.324\n",
      "==============================================================================\n",
      "Omnibus:                       78.812   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1272.922\n",
      "Skew:                           4.959   Prob(JB):                    3.88e-277\n",
      "Kurtosis:                      29.172   Cond. No.                     2.37e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.37e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "reg1 = sm.OLS(endog=ticker_df['excess_return'], exog=ticker_df[['ER1', 'ER2', 'G', 'B', 'SR', 'const']], missing='drop')\n",
    "results = reg1.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 volume   R-squared:                       0.176\n",
      "Model:                            OLS   Adj. R-squared:                  0.079\n",
      "Method:                 Least Squares   F-statistic:                     1.819\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):              0.148\n",
      "Time:                        00:04:35   Log-Likelihood:                -52.339\n",
      "No. Observations:                  39   AIC:                             114.7\n",
      "Df Residuals:                      34   BIC:                             123.0\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "volume1       -0.2524      0.168     -1.498      0.143      -0.595       0.090\n",
      "volume2       -0.2066      0.170     -1.216      0.232      -0.552       0.139\n",
      "G             -0.0170      0.009     -1.989      0.055      -0.034       0.000\n",
      "B              0.0237      0.022      1.088      0.284      -0.021       0.068\n",
      "const          0.7588      0.585      1.297      0.203      -0.430       1.948\n",
      "==============================================================================\n",
      "Omnibus:                       18.341   Durbin-Watson:                   1.929\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.500\n",
      "Skew:                           1.529   Prob(JB):                     1.30e-05\n",
      "Kurtosis:                       5.121   Cond. No.                         296.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "reg2 = sm.OLS(endog=ticker_df['volume'], exog=ticker_df[['volume1', 'volume2', 'G', 'B', 'const']], missing='drop')\n",
    "results2 = reg2.fit()\n",
    "\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             volatility   R-squared:                       0.029\n",
      "Model:                            OLS   Adj. R-squared:                 -0.086\n",
      "Method:                 Least Squares   F-statistic:                    0.2514\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):              0.907\n",
      "Time:                        00:04:36   Log-Likelihood:                 124.41\n",
      "No. Observations:                  39   AIC:                            -238.8\n",
      "Df Residuals:                      34   BIC:                            -230.5\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "VOL1           0.0120      0.172      0.070      0.945      -0.337       0.361\n",
      "VOL2          -0.1406      0.171     -0.821      0.418      -0.489       0.208\n",
      "G          -3.653e-05   9.33e-05     -0.392      0.698      -0.000       0.000\n",
      "B           -3.61e-05      0.000     -0.159      0.875      -0.000       0.000\n",
      "const          0.0113      0.007      1.723      0.094      -0.002       0.025\n",
      "==============================================================================\n",
      "Omnibus:                       78.420   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1248.841\n",
      "Skew:                           4.927   Prob(JB):                    6.57e-272\n",
      "Kurtosis:                      28.912   Cond. No.                     8.16e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.16e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "reg3 = sm.OLS(endog=ticker_df['volatility'], exog=ticker_df[['VOL1', 'VOL2', 'G', 'B', 'const']], missing='drop')\n",
    "results3 = reg3.fit()\n",
    "\n",
    "print(results3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./regression results/'+'CSCO hourly'+' excess return.txt', 'w') as fh1:\n",
    "    fh1.write(results.summary().as_text())\n",
    "with open('./regression results/'+'CSCO hourly'+' volume.txt', 'w') as fh2:\n",
    "    fh2.write(results2.summary().as_text())\n",
    "with open('./regression results/'+'CSCO hourly'+' volatility.txt', 'w') as fh3:\n",
    "    fh3.write(results3.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
